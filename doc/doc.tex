\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts

\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{enumitem}

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

\begin{document}

\title{Measuring Properties of a CCD Spectrograph}

\author{\IEEEauthorblockN{Kryštof Havránek}
\IEEEauthorblockA{\textit{Course: Space Engineering \the\year} \\
\textit{Czech Technical University in Prague}\\
Technicka 2, Prague, Czech Republic \\
havrakry@fel.cvut.cz}
\and
\IEEEauthorblockN{Martin Jelínek}
\IEEEauthorblockA{\textit{Course: Space Engineering \the\year} \\
\textit{Astronomical Institute of the CAS}\\
Fričova 298, Ondřejov, Czech Republic \\
martin.jelinek@asu.cas.cz}
}

\maketitle

\begin{abstract}
This paper presents an analysis of the parameters of the Coudé CCD 700~mm spectrograph connected to the Perek 2-meter optical telescope at the Ondřejov Observatory.
Zero, dark, and flat-field frames were acquired and processed in order to estimate noise parameters, pixel uniformity, and sensor gain.
\end{abstract}

\section{Introduction}

One of the primary tools used to investigate the physical properties of celestial objects is astronomical spectroscopy.
This technique enables the determination of stellar temperatures, chemical composition, radial velocities, and other fundamental parameters by dispersing incoming light into its constituent wavelengths.
Modern spectroscopic observations rely on large-aperture telescopes combined with sensitive CCD detectors.
The scientific quality of CCD-based observations depends not only on the optical system but also on a precise understanding of detector behavior and noise sources, as well as on proper calibration procedures \cite{Martinez2001}.

This protocol begins by describing the instrumental setup and theoretical background relevant to spectroscopic observations carried out with the Ondřejov 2-m telescope.
Particular emphasis is placed on the principles of spectrograph operation, CCD detector characteristics, and the main noise sources affecting the acquired data.
This theoretical foundation provides the basis for the data reduction and analysis steps described in later sections.

\section{Perek 2~m Telescope}

The Perek 2~m telescope, operated by the Astronomical Institute of the Czech Academy of Sciences, is an optical telescope built as a classical Coudé reflector with a 2~m primary mirror.
The telescope provides a combination of high light-gathering power and mechanical stability, making it well suited for high-resolution spectroscopic observations of relatively faint stars \cite{Ondrejov2m}.

In the Coudé configuration, incoming light is reflected by the primary mirror onto the secondary, which then directs it via flat mirrors to the Coudé focus (see Figure~\ref{fig:layout_telescope}).
From the telescope, three optical fibers guide the light to two different spectrographs: an echelle spectrograph and a single-order spectrograph with a configurable focal length (referred to as the Coudé spectrograph).
Currently only setup for 700~mm focal length is being used a this one is the focus of this paper.

The telescope is equipped with accurate guiding and tracking systems.
This is essential in order to prevent image drift during long exposures when using narrow entrance slits or optical fibers.

\begin{figure}[htbp]
\centering
\includegraphics[width=0.95\columnwidth]{../img/schema_coude.png}
	\caption{Optical layout of the Perek 2~m Telescope\cite{Ondrejov2m}}
\label{fig:layout_telescope}
\end{figure}

\section{Spectrograph}

A spectrograph is an optical instrument designed to disperse incoming light into its constituent wavelength components.
In the field of scientific spectroscopy, this dispersion is typically achieved using a diffraction grating.
A grating is an optical element featuring hundreds of periodic grooves.
It's basic working principle is essentially the same as effect seen in a double-slit experiment -- it exploits constructive interference to create maxima and minima for each wavelength.
Different wavelengths are diffracted from the grating at different angles, where following equation must be satisfied:
\begin{equation}
	d \sin \theta_m = m \lambda,
\end{equation}
where $d$ is the groove spacing, $\theta_m$ is the diffraction angle at which a maximum occurs, $\lambda$ is the wavelength of light, and $m$ is an integer denoting the spectral order.
Spectral orders can lead to multiple wavelengths overlapping with each other (see Figure~\ref{img:spectral_orders}).
For example, the first spectral order of light with wavelength $\lambda$ will fall on the same location as the second order of wavelength $\lambda/2$ \cite{tau_hydrogen_2018}.

\begin{figure}[htbp]
\centering
\includegraphics[width=0.7\columnwidth]{../img/spectral_orders.png}
\caption{Diffraction orders produced by a grating for multiple wavelengths \cite{tau_hydrogen_2018}}
\label{img:spectral_orders}
\end{figure}

In order to prevent overlap between spectral orders, several different construction techniques can be used.
Echelle-type spectrographs use a cross-dispersing element to spatially separate diffraction orders on the detector.
This enables the measurement of a very wide spectrum in a single exposure \cite{Eversberg2015}.
A simpler approach is to use filters to block out light of wavelengths that would interfere with the observation.
It is also possible to conduct observations in an order where potentially interfering wavelengths fall below the sensitivity range of the CCD detector or the transmission limits of the optical system itself.
The Coudé spectrograph connected to the Perek telescope employs both of these latter approaches \cite{Ondrejov2mCZ}.

\subsection{Coudé Spectrograph}
The Coudé spectrograph at the Ondřejov Observatory operates as a single-order spectrograph, functioning in either the first or the second order depending on the wavelength range being observed (see Table~\ref{tab:spec_orders}).
The basic components of the spectrograph include an entrance slit or fiber, a collimator, a dispersive element, a camera system, and a detector, as shown in Figure~\ref{img:layout_spectograph}.

\begin{table}[htbp]
\caption{Coudé Spectrograph Operating Range}
\begin{center}
\begin{tabular}{|c||c|c|}
\hline
	 Spectral order & $\lambda_\mathrm{min}$ ($\AA$) & $\lambda_\mathrm{max}$ ($\AA$) \\
\hline
	1 & 5100 & 9100 \\
\hline
	2 & 3700 & 5100 \\
\hline
\end{tabular}
	\label{tab:spec_orders}
\end{center}
\end{table}

Light enters the spectrograph through the slit and is collimated into a parallel beam.
The beam then encounters the diffraction grating, which separates the light according to wavelength.
Next, the dispersed light is focused onto the CCD detector by Schmidt camera optics, where the spectrum is recorded.
A Schmidt camera is used to minimize distortion of the spectrum towards the edges of the sensor.

\begin{figure}[htbp]
\centering
\includegraphics[width=0.95\columnwidth]{../img/schema_coude_spec.png}
	\caption{Optical layout of the Coudé spectrograph\cite{Ondrejov2m}}
\label{img:layout_spectograph}
\end{figure}

The detector system consists of a PyLoN eXcelon CCD assembly utilizing an E2V 42-10 BX chip.
The chip is cooled using liquid nitrogen to an operating temperature of $-115^\circ$C.
For calibration a Thorium-Argon reference lamp is installed and driven at 15~mA \cite{Ondrejov2m}.

\section{CCD Detector Fundamentals}

Charge-Coupled Devices (CCDs) are widely used in astronomical spectroscopy as they are well-suited for the detection of faint astronomical signals and for applications requiring precise spectroscopic and photometric measurements.
This is due to their properties, which include high quantum efficiency, linear response over a wide dynamic range, and relatively low noise characteristics.
In contrast to CMOS sensors, CCDs generally offer better pixel-to-pixel consistency, as all pixels share common readout circuitry.
Consequently, CCD sensors generally exhibit less fixed-pattern noise than CMOS detectors.

The basic operating principle is that incident photons interact with the silicon substrate, generating photoelectrons via the photoelectric effect.
The number of generated electrons is therefore proportional to the incident photon flux and the detector's quantum efficiency.
These photoelectrons accumulate in potential wells associated with individual pixels during the exposure time.
Then, using a sequence of clocked voltage shifts, the stored charge is transferred across the detector, amplified, and read out using an ADC \cite{Moore2014}.

The CCD gain determines the conversion between the number of electrons and the recorded ADU value, expressed in units of electrons per ADU:
\begin{equation}
S_{e^-} = g \cdot S_{\text{ADU}},
\label{eq:gain_def}
\end{equation}
where $g$ is the gain in $\mathrm{e}^{-}\mathrm{ADU}^{-1}$ and $S_{\text{ADU}}$ is the recorded signal in ADU.
Knowledge of the sensor's gain is essential for converting measured signals into physically meaningful quantities and for correctly estimating the contributions of different noise sources.
An incorrect gain value can lead to systematic errors in noise estimation and subsequently in signal-to-noise ratio calculations, affecting the reliability of scientific results \cite{Martinez2001}.

Under ideal conditions the gain is constant and thus the CCD sensor behaves linearly.
However, gain can sometimes be a function of the incoming light intensity or other parameters.
Furthermore, even when gain is quite independent on light intensity, deviations from linearity may still occur at very low signal levels due to electronic effects and especially near full-well capacity due to saturation.
Consequently, linearity tests are commonly performed to verify the operational range of the detector \cite{Martinez2001}.

In addition to gain and linearity, CCD performance is influenced by pixel-to-pixel variations in sensitivity.
These variations arise from manufacturing imperfections and are corrected using calibration frames \cite{Moore2014}.
Understanding the physical operation of CCD detectors and their fundamental characteristics is therefore essential for the correct interpretation of spectroscopic data and forms the basis for the calibration and noise analysis procedures described in subsequent sections.

\subsection{Noise Sources in CCD Detectors}

Several independent noise sources affect measurements performed with CCD detectors.
The main contributions are read noise, dark current noise, and photon noise.
A clear understanding of the physical origin and statistical properties of these noise sources is essential for interpreting CCD data and for optimizing observational strategies.

Read noise is introduced during the electronic readout process of the CCD and is independent of the exposure time.
It originates from multiple electronic components, such as the output amplifier, the charge-to-voltage conversion stage, or the analog-to-digital converter.
Fluctuations in the readout process lead to uncertainty in the measured signal, even in the absence of incident light.

Read noise is typically characterized using bias (zero-exposure) frames, which record the electronic offset and readout fluctuations of the detector.
By analyzing the statistical dispersion of pixel values across multiple bias frames, the read noise can be estimated on a pixel-by-pixel basis or as a global detector parameter.
Read noise limits performance at low signal levels, where it can dominate over other noise sources and significantly reduce the signal-to-noise ratio.
This occurs because read noise does not depend on exposure time -- thus as the collected signal increases, the relative contribution of read noise decreases.
To achieve reliable measurements, read noise must be minimized for short exposures or observations of faint sources.
Read noise typically follows a Gaussian distribution, as it originates from the sum of many independent electronic processes in the readout chain \cite{Moore2014}.

Dark current noise arises from thermally generated electrons within the silicon lattice of the CCD, even when no light is incident on the detector.
As a result, dark current introduces an additional signal that accumulates linearly with exposure time.
Dark current strongly depends on detector temperature and can increase rapidly with even slight temperature changes.
To minimize this, CCD detectors are commonly cooled, preventing temperature fluctuations and reducing the dark current and associated noise.
In detectors equipped with effective cooling systems, the contribution of dark current noise may become negligible compared to other noise sources.
Dark current noise follows Poisson statistics \cite{FellersDavidson}.

Finally, the third major noise source is photon noise.
It originates from the statistical nature of photon arrival at the detector and is therefore not a property of the detector itself.
The number of detected photons fluctuates from one exposure to another even for a constant light source, since photon arrival follows Poisson statistics.
The uncertainty these fluctuations contribute to the detected signal cannot be eliminated by calibration \cite{Martinez2001}.
Photon noise becomes the dominant noise source at high fluxes since it increases with signal intensity.

Finally, these different noise sources must be considered together.
Assuming the noise sources are statistically independent, their variances sum up linearly, meaning the total noise is the quadratic sum of the individual components \cite{Newberry1996}.
This can be expressed as:
\begin{equation}
\sigma_{\text{total}}^{2} = \sigma_{\text{read}}^{2} + \sigma_{\text{dark}}^{2} + \sigma_{\text{shot}}^{2}.
\label{eq:total_noise}
\end{equation}
Understanding which noise source dominates under given observational conditions is essential for designing efficient observing strategies and for interpreting the measured data.

\subsection{Calibration Frames}

Different types of calibration frames are essential for estimating sensor properties and separating the true astronomical signal from detector and instrument-related artifacts.
The most common types are bias (zero) frames, dark frames, and flat-field frames.

Bias or zero-exposure frames are used to measure the electronic offset introduced during the readout process and to characterize the read noise of the detector.
Since bias frames are acquired with no light incident on the CCD, they contain only the electronic bias level (fixed pattern) and readout fluctuations.
By combining multiple bias frames, a master bias frame can be constructed.
This master frame is subsequently subtracted from all other images to remove the sensor's fixed pattern bias \cite{Moore2014}.

Dark frames are acquired with the same exposure time and detector temperature as the science observations but without any incident light.
They are used to characterize the dark current and its associated noise.
The accumulated dark signal increases linearly with exposure time and depends strongly on detector temperature.
Dark frames also capture fixed-pattern components of the dark signal, such as hot pixels.
These artifacts can be removed by subtracting a master dark frame from the data \cite{Martinez2001}.

Flat-field frames are used to correct for pixel-to-pixel sensitivity variations and large-scale illumination gradients across the detector, as well as to estimate the sensor's gain.
Usually, uniform illumination of the sensor is required to ascertain these parameters.
However, due to the inherent nature of spectrographs, where light is dispersed into its constituent wavelengths, achieving completely uniform illumination is impossible \cite{Robertson_2021}.
This introduces significant complications for flat-field analysis.

\section{Bias Frame Analysis}

Fifteen bias frames were acquired at the shortest possible exposure time.
The exact duration in seconds is not precisely known, as camera limitations induce a fixed readout delay.
Based on subsequent dark frames, this delay was estimated to be approximately 0.5 seconds.
However, for the purpose of analyzing bias frames, the exact value is unimportant, and a precise offset estimation was not an objective anyway.

The analysis of bias frames from the spectrograph is relatively straightforward.
First, a median frame was created to characterize any fixed-pattern noise the CCD might exhibit.
A median combination is used instead of average to prevent the master frame from being influenced by high-energy particles (cosmic rays) that might have impacted the sensor during the short observation window and skewed the results.
Basic statistics were calculated for both the master frame and the full stack of bias frames, as shown in Table~\ref{tab:zero}.

\begin{table}[htbp]
\caption{Bias Frame Analysis Results}
\begin{center}
\begin{tabular}{|c||c|c|}
\hline
	\textbf{Data} & $\mu$ (ADU) & $\sigma$ (ADU) \\
\hline
\hline
	Master frame & 600.15 & 1.18 \\
\hline
	All bias frames & 600.14 & 3.62 \\
\hline
\end{tabular}
	\label{tab:zero}
\end{center}
\end{table}

The results indicate that the readout noise is quite low.
Furthermore, the very low standard deviation within the master frame suggests that the sensor does not exhibit much of a noticeable fixed-pattern (visualized in Figure~\ref{img:master_bias}).
The histograms below display the statistics calculated for the master frame (Figure~\ref{img:master_zero}) and for the entire stack of bias frames (Figure~\ref{img:zero_stack}).
Since high-energy particles impacted the sensor in some individual frames, the second histogram is limited to a maximum of 625~ADU to preserve detail.
Despite these outliers, it is clearly visible that the measured noise follows the expected Gaussian distribution.

\begin{figure}[htbp]
	\begin{center}
		\includegraphics[width=0.48\textwidth]{../img/zero_master_frame.png}
	\end{center}
	\caption{Master Zero Frame}
\label{img:master_bias}
\end{figure}

\begin{figure}[htbp]
	\begin{center}
		\includegraphics[width=0.4\textwidth]{../img/zero_master_uniformity.png}
	\end{center}
\caption{Master Zero Frame Uniformity}
\label{img:master_zero}
\end{figure}

\begin{figure}[htbp]
	\begin{center}
		\includegraphics[width=0.4\textwidth]{../img/zero_stack_uniformity.png}
	\end{center}
\caption{Total Zero Stack Noise Distribution}
\label{img:zero_stack}
\end{figure}

\section{Dark Frame Analysis}

A total of four dark frames were acquired, each with a one-hour exposure time.
First, the master zero frame was subtracted from all dark frames to remove any fixed-pattern bias, regardless of its magnitude.
Several properties were then analyzed, including dark current characteristics, the number of hot pixels, and transient events (which required filtering).

A threshold for hot pixels was defined as any value exceeding 5 times the standard deviation of the master dark frame, following the method described by \cite{KennedyYoung2020}.
In individual dark frames, it is difficult to distinguish between high-energy particles impacting the sensor (cosmic rays) and true hot pixels.
Therefore, this analysis was performed only on the master dark frame, as hot pixels consistently exhibit values significantly higher than the mean in all images.
Using a threshold of $5\sigma$, 252 hot pixels were identified, comprising 0.024\% of the CCD sensor area.
Had a more conservative threshold of $10\sigma$ been used, only 17 pixels would have met the criteria.
This indicates that the sensor exhibits excellent thermal noise uniformity.

Some of these hot pixels fall within areas illuminated by light from the dispersive grating.
However, as the majority of pixels (177, or 69.4\%) are isolated and do not form larger clusters.
Thus, their impact on measurements should be negligible.
The remaining 77 pixels have other hot pixels in their vicinity (verified by performing a 2D convolution with a $5 \times 5$ uniform kernel).
The largest groups contain up to 10 adjacent pixels, which may indicate small manufacturing defects.
The locations of these pixels are shown in Figure~\ref{img:hot_pixels}, where each point has been dilated by 30 pixels to ensure visibility.

\begin{figure}[htbp]
	\begin{center}
		\includegraphics[width=0.48\textwidth]{../img/dark_hot_pixels_big.png}
	\end{center}
\caption{Hot Pixels Locations}
\label{img:hot_pixels}
\end{figure}

Aside from static hot pixels, transient events were also detected.
As previously noted, while hot pixels exhibit high values in all dark frames, pixels affected by transient events (such as cosmic rays or background radiation) appear "hot" only in a single frame.
By comparing the maximum value of each pixel across the dark stack to the median dark frame, approximately 707 pixels were found to exceed a threshold of 1000~ADU due to transient events.

Regarding the statistical properties of the dark frames, the master dark frame exhibits a low standard deviation of 2.01~ADU, with an average value of 1.89~ADU.
The standard deviation calculated over all individual frames is 6.77~ADU.
When transient events are excluded, this drops to 6.02~ADU.
Verifying whether the measured data follows the expected distribution is challenging.
Shot noise associated with dark current should exhibit a Poisson distribution.
However, because its variance is quite small, comparable to that of the read noise, it is difficult to accurately separate the two noise sources.
Although the variance of the read noise (from the master zero) is known, this noise remains present in the dark frames and cannot be easily subtracted.

In order to express dark current in physical units ($e^{-}\mathrm{s}^{-1}$), a gain value of $0.6114~\mathrm{e}^{-}\mathrm{ADU}^{-1}$, estimated in subsequent sections, was used.
Using this gain, the mean dark current was calculated as $0.255 \times 10^{-3}~\mathrm{e}^{-}\mathrm{s}^{-1}\mathrm{px}^{-1}$ with a standard deviation of $0.342 \times 10^{-3}~\mathrm{e}^{-}\mathrm{s}^{-1}$.
As we can see $\mu \neq \sigma^2$, which is inconsistent with the expected Poisson statistics, but as stated separation of different noises is difficult.
The distribution of dark current, overlaid with a Poisson distribution curve for calculated $\sigma$, is shown in Figure~\ref{img:dark_distribution}.

\begin{figure}[htbp]
	\begin{center}
		\includegraphics[width=0.47\textwidth]{../img/dark_current_distribution.png}
	\end{center}
\caption{Dark Current Distribution}
\label{img:dark_distribution}
\end{figure}

\section{Gain Calculation}

In order to estimate the gain, 60 images were acquired using different exposure times and four different illumination intensities.
The light source used was ambient light within the telescope dome.
Different light intensities were achieved by offsetting the optical fibers that guide light to the spectrograph relative to each other.
Consequently, no prior information regarding the relative differences between these intensities was available.

Basic idea for noise calculation stems from the fact that arriving photons exhibit a Poisson distribution.
Normally for a Poisson distribution mean value and variance are equal to each other.
However when amplification/attenuation is present this doesn't hold true and gain value needs to be included into equation.
If we also add influence of other noises (here just read noise $\sigma_\mathrm{ro}^2$) we get an equation
\begin{equation}
	g\cdot \sigma = \sqrt{\overline{x}\cdot g + \sigma_\mathrm{ro}^2}.
	\label{eq:gain_eq}
\end{equation}
Here, $\overline{x}$ represents the mean signal value in ADU, $\sigma$ is its standard deviation in ADU, and $g$ is the gain in $e^-\mathrm{ADU}^{-1}$.

For the purpose of numerical calculation, this equation is often rearranged as:
\begin{equation}
	\sigma^2 = \frac{\overline{x}}{g} + \frac{\sigma_\mathrm{ro}^2}{g^2}.
	\label{eq:numer_gain}
\end{equation}
This formulation describes a linear relationship between the variance ($\sigma^2$) and the mean signal ($\overline{x}$), where the slope is the inverse of the gain ($1/g$).

In setups where uniform flat-field illumination is possible, a reliable gain estimate can be derived from just a small set of images \cite{irafGain}.
Variances can be calculated spatially across pixels, provided their properties are similar.
However, the Coudé spectrograph at Ondřejov does not allow for easy modification of the optical path to ensure uniform illumination of the sensor.
Incoming light must still pass through the dispersive grating.
Consequently, different parts of the spectrograph are illuminated with different wavelengths (However the possible influence of quantum efficiency is neglected).
Since the light source does not have a constant spectrum, the illumination is strictly non-uniform.
Furthermore, only a small fraction of the sensor is actually illuminated.
Specifically two thin strips corresponding to the two optical fibers, while the majority of the sensor area remains unilluminated.

\subsection{Inter-Frame Flat-field Analysis}

The first approach tested for calculating gain involved computing variances and means over groups of images with identical exposure times and illumination level.
Following the method described by \cite{Robertson_2021}, variances were calculated for each pixel independently across the image stack, rather than over groups of spatially adjacent pixels.
After subtracting the master zero frame, images were grouped by illumination level and exposure time.
Statistical properties were then calculated for groups containing more than one image.

While a simple outlier rejection method based on an $\overline{x} \pm n\sigma$ threshold was deemed sufficient for transient event detection in dark frames, a more robust rejection method was implemented here.
This was necessary because individual bins contained few data points, meaning the standard deviation could be significantly skewed by outliers, leading to ineffective rejection.
Instead, the Median Absolute Deviation (MAD) was utilized.
MAD relies on the median, rendering it far less sensitive to outliers, though the basic principle remains similar to classical thresholding.
Since the mean signal values are sufficiently large for the Central Limit Theorem to apply, the noise distribution approximates a Gaussian \cite{Walpolec2002}.
Consequently, the standard MAD scaling factor of 1.4826 was maintained, while the cutoff value was determined empirically based on the data histogram.

A major limitation of this approach was that the dataset contained multiple images for the same configuration only at short exposure times (below 10 seconds).
Consequently, only values under 6000~ADU were included in the gain calculation (see Figure~\ref{img:interframerobust}).
This was deemed insufficient, as the saturation limit of the 16-bit ADC is more than ten times higher.

\begin{figure}[htbp]
	\begin{center}
		\includegraphics[width=0.46\textwidth]{../img/flat_interframe_robust.png}
	\end{center}
\caption{Photon Transfer Curve -- Inter-Frame Analysis}
\label{img:interframerobust}
\end{figure}

A gain value of $g=0.1915~\mathrm{e}^{-}\mathrm{ADU}^{-1}$ was calculated using this method.
Due to the limitations of this approach, confidence intervals were not calculated, and the read noise term was not set to scale with $1/g^2$ in the fit.
Nevertheless, it is apparent that the sensor does not exhibit the expected linear behavior, suggesting its gain is not perfectly constant.
Specifically, there is a visible trend where some variances at low ADU levels increases much faster than expected.
Alternatively, it is possible that the fiber alignment was not perfectly stable, causing spectral lines to shift slightly between exposures, artificially inflating the variance.

\subsection{Spatial Flat-field Analysis}

Since pixel properties are expected to be relatively constant across the sensor, an attempt was made to estimate the gain by calculating statistical properties within individual frames (spatial variance).
Because different wavelengths are dispersed along the X-axis, grouping pixels in this direction would be incorrect.
But along the Y-axis, the signal corresponds to the spatial profile of the optical fiber -- so a much more gradual change is to be expected.
However, even in Y direction the illumination is far from constant, not to mention only a small part of sensor is illuminated.
Still if the gain values calculated using this method were somewhat constant it was thought this method might provide some useful data.

Regardless, as shown in Table~\ref{tab:spatial_flat}, the estimated gain value changes significantly with bin size.
Furthermore, visualizing the binned data reveals that the expected trend is absent (see Figure~\ref{img:flat_spatial_robust}).

\begin{table}[htbp]
\caption{Spatial Flat-field Analysis Gain Estimates}
\begin{center}
\begin{tabular}{|c|c|}
\hline
	 Bin Height (px) & Gain ($\mathrm{e}^{-}\mathrm{ADU}^{-1}$) \\
\hline
\hline
2 & 0.1211 \\
\hline
3 & 0.0854 \\
\hline
4 & 0.0826 \\
\hline
5 & 0.0401 \\
\hline
\end{tabular}
	\label{tab:spatial_flat}
\end{center}
\end{table}

\begin{figure}[htbp]
	\begin{center}
		\includegraphics[width=0.4\textwidth]{../img/flat_spatial_robust.png}
	\end{center}
\caption{Photon Transfer Curve -- Spatial Analysis, Bin Size = 3}
\label{img:flat_spatial_robust}
\end{figure}

\subsection{Residual Flat-field Analysis}

Upon a mentor's suggestion, a residual analysis method for gain estimation was attempted.
Instead of calculating variance between raw pixel values—whether between two images or within spatial bins—this method first creates a "noise-free" model of the illumination pattern.
The variance of the residuals (the difference between the observed data and this model) is then calculated.
The data processing algorithm proceeds in the following steps:

\begin{enumerate}[label=\Roman*.]
    \item Images are first grouped based on illumination intensity (i.e., by different fiber positions).
    \item Each group is then processed separately:
        \begin{enumerate}[label=\arabic*.]
            \item A model is created from the images in the group. This model is normalized to have a mean value of one.
            \item The model is scaled to match the flux level of each individual image.
            \item The residual for each pixel is calculated (Image $-$ Scaled Model).
            \item The value of the model is recorded as the signal level for each pixel.
        \end{enumerate}
    \item Stratified sampling is applied to reduce data volume while preserving statistical distribution.
    \item Outlier rejection is performed using the MAD.
    \item Local gain is calculated for each signal level.
		\item A global fit is performed using the equation (\ref{eq:numer_gain}).
\end{enumerate}

The main challenge of this method is the creation of an accurate, noise-free model.
This model is typically created by calculating the mean value for each pixel over a set of images.

One approach was to use the largest set of images with the same exposure time.
In the processed dataset, this corresponds to the 10~s exposure time, in case of the illumination level with the most data.
Some illumination levels lack image pairs entirely, making averaging across a single exposure time impossible.
Theoretically, averaging $N$ identical images reduces the noise by a factor of:
\begin{equation}
	\sigma_N = \frac{\sigma}{\sqrt{N}}
	\label{eq:}
\end{equation}
where $\sigma_N$ is the noise deviation after averaging and $N$ is the number of averaged images \cite{Walpolec2002}.
With only nine 10~s frames available, the noise reduction is limited to approximately 67\%.

Since this specific model is created from relatively low ADU levels (peaking around 6000~ADU), the remaining noise causes significant errors when the model is scaled up to match higher-flux images.
Figure~\ref{img:flat_model_10s} shows the photon transfer curve resulting from this model.
It is apparent that the model works well for low values, where the points follow the expected square-root dependence.
However, for larger values, the model breaks down.
The failure of the model is also evident in the residual histograms (Figures~\ref{img:flat_hist_10s_med} and \ref{img:flat_hist_10s_3rd}), where not only is the shape of the curve incorrect, but the mean estimate is also clearly biased.

\begin{figure}[htbp]
	\begin{center}
		\includegraphics[width=0.4\textwidth]{../img/model_10s_photon_transfer_curve.png}
	\end{center}
\caption{Photon Transfer Curve -- Residual Analysis, 10~s Exposure Model}
\label{img:flat_model_10s}
\end{figure}

\begin{figure}[htbp]
	\begin{center}
		\includegraphics[width=0.4\textwidth]{../img/model_10s_histogram_med.png}
	\end{center}
\caption{Residual Histogram at Median, 10~s Exposure Model}
\label{img:flat_hist_10s_med}
\end{figure}

\begin{figure}[htbp]
	\begin{center}
		\includegraphics[width=0.4\textwidth]{../img/model_10s_histogram_3qar.png}
	\end{center}
\caption{Residual Histogram at 3rd Quantile, 10~s Exposure Model}
\label{img:flat_hist_10s_3rd}
\end{figure}

An attempt was also made to filter the model as a 1D signal (smoothing from top to bottom across the 512 pixels).
Since the illumination changes should be smooth in the vertical direction (parallel to the spectral lines) and previous sections showed that pixel-to-pixel deviations are small, this seemed a viable strategy.
However, this approach did not significantly improve the calculation.

Due to the failure of the model based on the most numerous exposure time, a new model based on the mean of all flat-field frames was used.
This model handles higher values much better, although it is still imperfect because the dataset contains significantly fewer images at higher exposure times.
Consequently, the noise contribution from high-flux images is less suppressed, and since their pixel values are much larger, they disproportionately influence the model estimate.

The next step in processing is scaling the model to each flat-field level.
This is straightforward, as the flat-field energy rises linearly with exposure time, as shown in Figure~\ref{img:exposure_time}.
A minor deviation from the most simple approach was to filter out unilluminated pixels when finding the scaling coefficient, as these would drag down the mean and lead to incorrect estimates.
In the model itself, these unilluminated regions are also zeroed so that their values do not rise after scaling, mimicking the behavior of real flat-fields at longer exposures.

\begin{figure}[htbp]
	\begin{center}
		\includegraphics[width=0.4\textwidth]{../img/exposure_time.png}
	\end{center}
\caption{Flat-field Levels vs Exposure Time, Different Illuminations}
\label{img:exposure_time}
\end{figure}
% \footnote{Different curves are for different illumination levels.}
After the model is scaled, residuals are calculated and stored.
In the following step, stratified sampling is applied to the points.
This reduces the data count from approximately 12~million to 2~million without introducing measurable error.
This sampling method splits the measured data into bins according to their signal level and selects a random subset of points from each bin.
Stratified sampling is necessary because the distribution of data points across signal levels is far from uniform.

Following stratified sampling, outlier rejection using MAD is applied.
Then, equation (\ref{eq:numer_gain}) is fitted to the cleaned data to calculate the gain, with the read noise fixed to the value determined from the zero frame analysis.

A gain value of $g = 0.6114 \pm 0.0045~\mathrm{e}^{-}\mathrm{ADU}^{-1}$ was estimated using this method.
This yields the photon transfer curve shown in Figure~\ref{img:model_photon_transfer_curve}.

\begin{figure}[htbp]
	\begin{center}
		\includegraphics[width=0.4\textwidth]{../img/model_photon_transfer_curve.png}
	\end{center}
\caption{Photon Transfer Curve -- Residual Analysis}
\label{img:model_photon_transfer_curve}
\end{figure}

Still it must be noted that the dataset has fundamental limitations.
A denser dataset with a more uniform distribution of exposure times might yield different results.
Figure~\ref{img:model_local_gain} shows the gain value calculated for each signal level individually.
Using the simpler equation $\sigma^2 = \overline{x}/g + \sigma^2_\mathrm{ro}$ combined with the low number of data points in each bin, a perfectly straight line cannot be expected.
However, it is clear that the gain estimation remains problematic.
This persists despite the overall good confidence interval of the global fit.
For this reason, gain linearity (gain as a function of intensity) was not explored further.

\begin{figure}[htbp]
	\begin{center}
		\includegraphics[width=0.4\textwidth]{../img/model_instantaneous_gain.png}
	\end{center}
\caption{Model Local Gain}
\label{img:model_local_gain}
\end{figure}

\section{Grating Position and Sensor Resolution}

The final parameter of the Coudé spectrograph to be examined was the relationship between the central wavelength, the grating orientation, and the linear dispersion (resolution), in order to verify the accuracy of the existing documentation \cite{Ondrejov2m}.
For this purpose, reference spectra of a ThAr lamp were acquired and compared against atlases of strong spectral lines for Thorium \cite{Palmer1952} and Argon \cite{Norlen19731201}.
Automating this task proved to be complex, as it required determining both the linear dispersion ($\AA\mathrm{px}^{-1}$) and the central wavelength ($\AA$) for each frame.
If a nearly linear relationship between the grating angle and the central wavelength is assumed, then three variables must be determined for the dataset: the slope ($\AA\mathrm{rad}^{-1}$), the intercept ($\AA$), and the linear dispersion ($\AA\mathrm{px}^{-1}$).

A method based on geometric hashing was employed.
First, triples of peaks were identified within the measured data, and the atlas was searched for peaks exhibiting the same relative distances.
For potential matches, the atlas spectrum was scaled and shifted, and a correlation score was calculated based on the signal overlap.
To make correlation less sensitive to small shifts a convolution with a Gaussian function was run on the reference spectrum.
However, this method failed to reliably identify the correct matches.
This was largely because the 15~mA ThAr lamp did not emit some spectral lines present in the atlas, while conversely, some lines captured in the spectra were missing from the atlas.

Consequently, spectral lines were matched manually on a few selected frames to derive the output parameters.
The results were found to generally correspond with those listed in the documentation, as shown in Tables \ref{tab:pos1} and \ref{tab:pos2}.

\begin{table}[htbp]
	\caption{The Ranges of Exposed Spectra -- First Order\cite{Ondrejov2m}}
\begin{center}
\begin{tabular}{|c|c||c|c|}
\hline
Grating Increment & Grating Angle (deg) & Min ($\AA$) & Max ($\AA$) \\
\hline
\hline
	5321 &  35.78 &  8401.4 &  8869.9 \\
\hline
	5430 &  35.25 &  8197.2 &  8666.3 \\
\hline
	6382 &  30.62 &  6406.2 &  6878.6 \\
\hline
	6457 &  30.25 &  6263.5 &  6736.0 \\
\hline
	6943 &  27.88 &  5328.6 &  5801.4 \\
\hline
\end{tabular}
	\label{tab:pos1}
\end{center}
\end{table}

\begin{table}[htbp]
	\caption{The Ranges of Exposed Spectra -- Second Order\cite{Ondrejov2m}}
\begin{center}
\begin{tabular}{|c|c||c|c|}
\hline
Grating Increment & Grating Angle (deg) & Min ($\AA$) & Max ($\AA$) \\
\hline
\hline
	4712 & 38.75 & 4758.8 & 4991.1 \\
\hline
	5040 & 37.15 & 4459.9 & 4693.4 \\
\hline
	5242 & 36.17 & 4273.7 & 4507.7 \\
\hline
\end{tabular}
	\label{tab:pos2}
\end{center}
\end{table}

\section{Conclusion}

The Coudé spectrograph mounted on the Perek 2-meter telescope exhibits favorable noise parameters, and the pixel response is generally uniform.
The read noise was measured at 3.62~ADU and was found to follow a Gaussian distribution without any anomalies across the sensor area.
The Mean dark current was $0.255 \times 10^{-3}~\mathrm{e}^{-}\mathrm{s}^{-1}\mathrm{px}^{-1}$ with a standard deviation of $0.342 \times 10^{-3}~\mathrm{e}^{-}\mathrm{s}^{-1}$.
Thus, it should not pose a major problem for long-exposure imaging, even for relatively faint objects.
The sensor also exhibited only a small number of hot pixels.

The gain calculation proved to be problematic due to the nature of the available dataset.
Simple inter-frame methods did not yield reliable results, as they covered only about one-tenth of the CCD's dynamic range.
Intra-frame methods were unsuitable due to the inherent nature of spectroscopic images, where flat-field illumination is non-uniform.
Finally, a residual analysis method was attempted, estimating the gain at $g = 0.6114 \pm 0.0045~\mathrm{e}^{-}\mathrm{ADU}^{-1}$.
However, the model employed in this method was imperfect.
Consequently, despite the low statistical uncertainty, the systematic error of this estimate may be significant.

\section*{Acknowledgment}

The author would like to thank the Astronomical Institute of the Czech Academy of Sciences for providing access to the Ondřejov Observatory facilities and for their support during the measurements.

\bibliographystyle{unsrt}
\bibliography{bibliography}

\end{document}
